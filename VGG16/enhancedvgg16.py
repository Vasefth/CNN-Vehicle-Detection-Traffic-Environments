# -*- coding: utf-8 -*-
"""EnhancedVGG16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yRS3FJ_PLjTeA3PAv8_U6hivCBjjlP66
"""

import tensorflow as tf
from tensorflow import keras
from keras.applications import VGG16
from keras.layers import Flatten, Dense, Input
from keras.models import Model
from keras.optimizers import Adam
from keras.preprocessing.image import img_to_array, load_img
from keras.models import load_model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import cv2
import os
import keras.backend as K
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# Define the path to the directory containing training images
IMAGES_PATH = os.path.sep.join(["/content/drive/My Drive/data/training_images"])
# Define the path to the CSV file containing annotations for bounding boxes
ANNOTS_PATH = os.path.sep.join(["/content/drive/My Drive/data/train_solution_bounding_boxes (1).csv"])
# Define the base output directory
BASE_OUTPUT = "output"
# Create the base output directory if it doesn't exist
os.makedirs(BASE_OUTPUT, exist_ok=True)
# Define the path to save the trained model
MODEL_PATH = os.path.sep.join([BASE_OUTPUT, "detector.h5"])
# Define the path to save the plot of training history
PLOT_PATH = os.path.sep.join([BASE_OUTPUT, "plot.png"])
# Define the path to save the list of test image filenames
TEST_FILENAMES = os.path.sep.join([BASE_OUTPUT, "test_images.txt"])

# loading dataset
# Read the contents of the annotations CSV file and split it into rows
rows = open(ANNOTS_PATH).read().strip().split("\n")

# Initialize lists to store data, targets, and filenames
data = []
targets = []
filenames = []

# Iterate through each row in the annotations data starting from the second row
for row in rows[1:]:
    # Split the row into individual values
    row = row.split(",")
    # Extract filename, bounding box coordinates (startX, startY, endX, endY)
    (filename, startX, startY, endX, endY) = row
    # Construct the path to the image
    imagePath = os.path.join(IMAGES_PATH, filename)
    # Read the image using OpenCV
    image = cv2.imread(imagePath)
    # Get the height and width of the image
    (h, w) = image.shape[:2]
    # Normalize the bounding box coordinates
    startX = float(startX) / w
    startY = float(startY) / h
    endX = float(endX) / w
    endY = float(endY) / h
    # Load and preprocess the image using Keras
    image = load_img(imagePath, target_size=(224, 224))
    image = img_to_array(image)
    # Append the preprocessed image, target coordinates, and filename to their respective lists
    data.append(image)
    targets.append((startX, startY, endX, endY, 1.0))  # Append confidence score
    filenames.append(filename)

# Convert the list of images to a NumPy array and normalize pixel values
data = np.array(data, dtype="float32") / 255.0
# Convert the list of targets to a NumPy array
targets = np.array(targets, dtype="float32")

# Split the data into training and testing sets along with filenames
split = train_test_split(data, targets, filenames, test_size=0.10, random_state=42)
(trainImages, testImages) = split[:2]
(trainTargets, testTargets) = split[2:4]
(trainFilenames, testFilenames) = split[4:]

# Save the list of testing filenames to a file
with open(TEST_FILENAMES, "w") as f:
    f.write("\n".join(testFilenames))

# Building the model architecture
# Load the VGG16 model pretrained on ImageNet, excluding the fully connected layers
vgg = VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))
# Freeze the weights of the pretrained VGG16 model
vgg.trainable = False
# Get the output of the VGG16 model
flatten = vgg.output
# Flatten the output of the VGG16 model
flatten = Flatten()(flatten)
# Add fully connected layers for bounding box regression
bboxHead = Dense(128, activation="relu")(flatten)
bboxHead = Dense(64, activation="relu")(bboxHead)
bboxHead = Dense(32, activation="relu")(bboxHead)
bboxHead = Dense(5, activation="sigmoid")(bboxHead)  # 4 coordinates + 1 confidence score

# Create a model that takes VGG16's input and predicts bounding box coordinates
model = Model(inputs=vgg.input, outputs=bboxHead)

# Initialize the learning rate
INIT_LR = 1e-4
# Define the number of epochs for training
NUM_EPOCHS = 30
# Define the batch size for training
BATCH_SIZE = 20

# Define custom metrics
def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

# Initialize the Adam optimizer with the specified learning rate
opt = Adam(learning_rate=INIT_LR)

# Compile the model with mean squared error loss and the Adam optimizer
model.compile(loss="mean_squared_error", optimizer=opt, metrics=["accuracy", precision_m, recall_m, f1_m])

# Print the summary of the model architecture
print(model.summary())

# Train the model
H = model.fit(
    trainImages, trainTargets,
    validation_data=(testImages, testTargets),
    shuffle=True,
    batch_size=BATCH_SIZE,
    epochs=NUM_EPOCHS,
    verbose=1
)

# Save the object detector model
model.save(MODEL_PATH, save_format="h5")

# Create a dictionary with the final values of each metric
scores = {
    "train_loss": H.history["loss"][-1],
    "val_loss": H.history["val_loss"][-1],
    "train_accuracy": H.history["accuracy"][-1],
    "val_accuracy": H.history["val_accuracy"][-1],
    "train_precision": H.history["precision_m"][-1],
    "val_precision": H.history["val_precision_m"][-1],
    "train_recall": H.history["recall_m"][-1],
    "val_recall": H.history["val_recall_m"][-1],
    "train_f1": H.history["f1_m"][-1],
    "val_f1": H.history["val_f1_m"][-1]
}

# Convert the dictionary to a DataFrame and display it
scores_df = pd.DataFrame([scores])
print(scores_df)

# Plot the training and validation loss over epochs
N = NUM_EPOCHS
plt.style.use("ggplot")
plt.figure()

# Plot the loss
plt.subplot(2, 2, 1)
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(loc="lower left")

# Plot precision
plt.subplot(2, 2, 2)
plt.plot(np.arange(0, N), H.history["precision_m"], label="train_precision")
plt.plot(np.arange(0, N), H.history["val_precision_m"], label="val_precision")
plt.title("Precision")
plt.xlabel("Epoch")
plt.ylabel("Precision")
plt.legend(loc="lower left")

# Plot recall
plt.subplot(2, 2, 3)
plt.plot(np.arange(0, N), H.history["recall_m"], label="train_recall")
plt.plot(np.arange(0, N), H.history["val_recall_m"], label="val_recall")
plt.title("Recall")
plt.xlabel("Epoch")
plt.ylabel("Recall")
plt.legend(loc="lower left")

# Plot F1-score
plt.subplot(2, 2, 4)
plt.plot(np.arange(0, N), H.history["f1_m"], label="train_f1")
plt.plot(np.arange(0, N), H.history["val_f1_m"], label="val_f1")
plt.title("F1-score")
plt.xlabel("Epoch")
plt.ylabel("F1-score")
plt.legend(loc="lower left")

plt.tight_layout()
plt.savefig(PLOT_PATH)
plt.show()