# -*- coding: utf-8 -*-
"""CorrectFasterR-CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1voDdnHXCgER3GP8SS6SCxEDbn8EDReW_
"""

import os
from tqdm import tqdm
import torch
import random
import torchvision
import numpy as np
import pandas as pd
import seaborn as sns
from torchvision import models
from collections import Counter
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
from IPython.display import display
from torchvision.ops import box_iou
from torchvision import transforms as T
from sklearn.metrics import confusion_matrix
from sklearn.metrics import average_precision_score
from sklearn.model_selection import train_test_split
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights

from google.colab import drive
drive.mount('/content/drive')

# Hyperparameters.
EPOCH = 4
CONF_TRESHOLD = 0.20

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
#!pip uninstall torchvision -y
#!pip3 install --upgrade torchvision==0.12

class CustDat(torch.utils.data.Dataset):
  def __init__(self, df, unique_imgs, indices):
    self.df = df
    self.unique_imgs = unique_imgs
    self.indices= indices

  def __len__(self):
    return len(self.indices)

  def __getitem__(self, idx):
    image_name= self.unique_imgs[self.indices[idx]]
    boxes= self.df[self.df.image == image_name].values[:, 1:].astype("float")
    img = Image.open("/content/drive/My Drive/data/training_images/" + image_name ).convert('RGB')
    labels = torch.ones((boxes.shape[0]), dtype = torch.int64)
    target ={}
    target["boxes"] = torch.tensor (boxes)
    target["labels"] = labels
    return T.ToTensor() (img), target

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights= 'FasterRCNN_ResNet50_FPN_Weights.COCO_V1')
#model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights= 'FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1')

num_classes = 2
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# Transformations.
def get_transform(train):
    transforms = []
    transforms.append(T.ToTensor())
    if train:
        # If you want, many different Data Augmentation
        # options are available for training phase.

        # transforms.append(T.RandomHorizontalFlip(0.5))
        # RandomHorizontalFlip is one of them, but you may want to see also:
        #   ColorJitter
        #   RandomGrayscale
        #   RandomAffine
        pass
    return T.Compose(transforms)

# Utils for train/test DataLoaders.
def collate_fn(batch):
    return tuple(zip(*batch))
def custom_collate(data):
  return data

dataset= pd.read_csv("/content/drive/My Drive/data/train_solution_bounding_boxes (1).csv")

unique_imgs=dataset.image.unique()

train_inds,test_inds=train_test_split(range(unique_imgs.shape[0]),test_size=0.1) # 10% test size

train_dl=torch.utils.data.DataLoader(CustDat(dataset,unique_imgs,train_inds),
                                     batch_size=8,
                                     shuffle=True,
                                     collate_fn=custom_collate,
                                     pin_memory=True if torch.cuda.is_available() else False)

test_dl=torch.utils.data.DataLoader(CustDat(dataset,unique_imgs,test_inds),
                                     batch_size=8,
                                     shuffle=True,
                                     collate_fn=custom_collate,
                                     pin_memory=True if torch.cuda.is_available() else False)

model.to(device) # Send model to GPU if available.


params = [p for p in model.parameters() if p.requires_grad] # Get all parameters that require grad.

optimizer= torch.optim.SGD(
    params,
    lr=0.001,
    momentum=0.9,
    weight_decay=0.0005
)

lr_scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer,
    step_size=3,
    gamma=0.1
)

# ------------------- Training step -------------------
print(f"Start training on {device} [...]")

def train_epoch(model, optimizer, data_loader, device, epoch):
        model.train()
        epoch_loss = 0
        for data in (tepoch :=tqdm(data_loader)):
            tepoch.set_description(f"Epoch {epoch}")

            imgs = list(d[0].to(device) for d in data) # Send imgs to GPU if available.
            targets = [{boxes: labels.to(device) for boxes, labels in d[1].items()} for d in data] # Send targets to GPU if available.


            loss_dict = model(imgs, targets) # Forward pass.
            loss = sum(v for v in loss_dict.values()) # Compute loss.


            epoch_loss += loss.cpu().detach().numpy() # Accumulate loss.

            optimizer.zero_grad() # Reset gradients.
            loss.backward() # Backward pass.
            optimizer.step() # Update model parameters.


            tepoch.set_postfix(epoch_loss=epoch_loss.item())


            # Delete loss object to free some memory.
            del loss
            # and free cache
            torch.cuda.empty_cache()

for epochs in range (EPOCH):
    train_epoch(model, optimizer, train_dl, device, epochs) # Train model.
    lr_scheduler.step() # Update learning rate.

def compute_ap(gt_boxes, gt_labels, pred_boxes, pred_scores, iou_threshold=0.40, class_label=1, device='cpu'):

    # Sort predictions by score
    sort_idx = torch.argsort(pred_scores, descending=True)
    pred_boxes = pred_boxes[sort_idx]
    pred_scores = pred_scores[sort_idx]

    print("gt_boxes shape:", gt_boxes.shape)
    print("gt_labels shape:", gt_labels.shape)
    print("pred_boxes shape:", pred_boxes.shape)
    print("pred_scores shape:", pred_scores.shape)

    # Compute IoU between predicted and ground truth boxes
    iou = box_iou(pred_boxes, gt_boxes)
    print("iou shape:", iou.shape)

    # Find the best matching ground truth box for each prediction
    match_idx = iou.argmax(dim=1)
    print("match_idx shape:", match_idx.shape)
    match_iou = iou[range(iou.shape[0]), match_idx]
    print("match_iou shape:", match_iou.shape)

    # Initialize true positive and false positive arrays
    tp = torch.zeros_like(pred_scores)
    fp = torch.zeros_like(pred_scores)

    # Keep track of which ground truth boxes have already been matched
    matched = torch.zeros(gt_boxes.shape[0], dtype=torch.bool)
    print("matched shape:", matched.shape)

    threshold = 0.55

    print("Before loop - pred_scores shape:", pred_scores.shape)
    print("Before loop - match_idx shape:", match_idx.shape)
    print("Before loop - matched shape:", matched.shape)

    # Loop over predictions
    for i in range(pred_scores.shape[0]):
        # If the prediction matches a ground truth box with IoU above the threshold
        if match_iou[i] >= iou_threshold:
            # If the ground truth box has not already been matched
            if match_idx[i] < matched.shape[0] and not matched[match_idx[i]]:
                # True positive
                tp[i] = 1
                matched[match_idx[i]] = True
            else:
                # False positive (duplicate detection)
                fp[i] = 1
        else:
            # False positive
            fp[i] = 1

    # Create true_labels and predicted_labels
    true_labels = gt_labels.cpu().numpy()
    predicted_labels = (pred_scores > threshold).cpu().numpy()

    # Ensure true_labels and predicted_labels have the same length
    min_len = min(len(true_labels), len(predicted_labels))
    true_labels = true_labels[:min_len]
    predicted_labels = predicted_labels[:min_len]

    # Compute the confusion matrix
    cm = confusion_matrix(true_labels, predicted_labels)

    # Plot the confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.title("Confusion Matrix")
    plt.show()

    #------------------- Precision and Average Precision -------------------

    # Calculate TP, FP, and FN
    tp_cumsum = torch.sum(tp).item()
    fp_cumsum = torch.sum(fp).item()
    fn_cumsum = gt_boxes.shape[0] - tp_cumsum  # Total ground truth boxes - True Positives

    # Calculate precision and Average Precision
    precision = tp_cumsum / (tp_cumsum + fp_cumsum) if (tp_cumsum + fp_cumsum) > 0 else 0
    ap = average_precision_score(true_labels, predicted_labels)

    print("Precision:", precision)
    print("Average precision:", ap)

    return ap, precision

def disp_imgs(dl):
    precision_list = []
    ap_list = []
    for data in dl:
        length = len(data)
        i=0
        for i in range(len(data)):
            imgs = data[i][0]
            targets = data[i][1]
            boxes = targets['boxes']
            boxes = boxes.type(torch.int)
            labels = targets['labels']
            i+=1

            output = model([imgs.to(device)])
            out_bbox = output[0]["boxes"]
            out_scores = output[0]["scores"]


            #Apply confidence threshold to filter out less confident predictions
            confidence_keep = out_scores >= CONF_TRESHOLD
            out_bbox = out_bbox[confidence_keep]
            out_scores = out_scores[confidence_keep]

            keep = torchvision.ops.nms(out_bbox, out_scores, 0.40) # Apply NMS to further filter out predictions.

            im = (imgs.permute(1, 2, 0).cpu().detach().numpy() * 255).astype('uint8')
            vsample = Image.fromarray(im)
            draw = ImageDraw.Draw(vsample)

            for box, score in zip(out_bbox[keep],out_scores[keep]):  # Draw rectangles and confidence scores.
                draw.rectangle(list(box), fill=None, outline="red")
                draw.text((box[0], box[1]), f"Conf: {score:.2f}", fill="white")
            for box in boxes:       # Draw ground truth bounding boxes.
                draw.rectangle(list(box), fill=None, outline="green")
            display(vsample)

            result  = compute_ap(boxes.to(device), labels.to(device), out_bbox[keep].to(device), out_scores[keep].to(device), class_label=1, device=device) # Compute AP, precision.

            ap, precision = result[0], result[1]
            precision_list.append(precision)
            ap_list.append(ap)

    print("precision_mean: ", np.mean(precision_list))
    print("ap_mean: " , np.mean(ap_list))

model.eval()
data=iter(test_dl).__next__()
disp_imgs(test_dl)

import glob
jpgfiles = []
for file in glob.glob("/content/drive/My Drive/data/testing_images/*.jpg"):
    jpgfiles.append(file)

test_imgs = []
for j in range(len(jpgfiles)):
    test_img = Image.open(jpgfiles[j]).convert('RGB')
    test_img = T.ToTensor()(test_img)
    test_imgs.append(test_img)

print(len(test_imgs[:10]))

def disp_test_imgs(dl):
    for k in range(len(dl)):
        output = model([dl[k].to(device)])
        out_bbox = output[0]["boxes"]
        out_scores = output[0]["scores"]
        keep = torchvision.ops.nms(out_bbox, out_scores, 0.45)
        im = (dl[k].permute(1, 2, 0).cpu().detach().numpy() * 255).astype('uint8')
        vtest = Image.fromarray(im)
        draw = ImageDraw.Draw(vtest)
        for box, score in zip(out_bbox[keep],out_scores[keep]):  # Draw rectangles and confidence scores.
                draw.rectangle(list(box), fill=None, outline="red")
                draw.text((box[0], box[1]), f"Conf: {score:.2f}", fill="white")
        display(vtest)

np.random.shuffle(test_imgs)
disp_test_imgs(test_imgs[:10])

